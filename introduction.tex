\section{Introduction}
\label{sec:intro}

Modern approaches in Epistemic Logic~\cite{vonWright:1951,Hintikka:1962} have shifted focus from a single notion of knowledge (usually, the notion of \emph{knowing that}) to a diverse palette of notions, each of them tailored to specific purposes. In this regard, the notion of \emph{knowing how} has received significant attention, since it captures scenarios related to intelligent agents and its strategic behaviour. Logically, knowing how is typically defined as the ability of an agent to achieve a certain goal.  Knowing-how logics have direct applications to \emph{planning} problems \cite{Stuart21},  where  plans have to be constructed such that a collection of agents can achieve a given goal.  Examples of planning applications can be found in self-driven cars,  robotics, software engineering, etc.

Usually,  the semantics for knowing how logics can be thought as as a combination of operators that describe abilities alongside standard epistemic operators for knowing that.  This is the approach introduced in, e.g.~\cite{Mccarthy69,Moore85,Les00,Hoek00,HerzigT06}. As a result, knowing how is seen as \emph{the agent knows that there is a course of action leading to achieve the intended goal}. However, this reading is not entirely accurate, as pointed out in e.g.~\cite{JamrogaA07,Herzig15}. Instead, knowing how should be read as \emph{there is a course of action, that the agent knows how to apply, to bring about the goal}. Thus, a novel perspective emerged in~\cite{Wang15lori,Wang16,Wang2016}, where a new modality is formally defined with the aim of capturing the proper reading of knowing how. 

More specifically, the new modality considered by~\cite{Wang15lori,Wang16,Wang2016} is a binary modality $\kh(\psi,\varphi)$ interpreted over Labeled Transition Systems (LTS), where an LTS represents the  actions that are available for an agent and their effects. Thus, $\kh(\psi,\varphi)$ holds if there exists a sequence of actions $\plan$ (i.e., a \emph{plan}) such that in every situation where $\psi$ holds, $\plan$ can be executed, it never aborts its execution, and it always leads to situations in which $\varphi$ holds. This new view of knowing how raised a new family of logics refining the original one, witnessed by the extensive related literature (see e.g.~\cite{LiWang17,Li17,Li17bis,FervariHLW17,LiW21,NaumovT18,NaumovT19,Naumov2018a}). Moreover, in~\cite{AFSVQ21,AFSVQ23} the original approach is enriched by a notion of `epistemic indistinguishability' between plans, arguably closer to standard semantics of epistemic logics. This indistinguishably relation indicates that all the related plans are considered or perceived ``equally good''
from the agent's perspective (even if they are not), thus a plan $\plan$ is suitable for achieving a goal if this is also the case for all the plans that are indistinguishable from $\plan$. The new semantics arguably offers a more epistemic perspective on knowing how compared to the original approach.

The above-mentioned works investigate various logical properties, including axiomatizations, expressivity, and the complexity of the mentioned logics. In particular, the model-checking problem results of interest, since it is  ubiquitous in software verification. Moreover, as argued in~\cite{DemriF23}, the model-checking problem better reflects the real power of the logics. This is because these logics often have a simple syntax combined with a rich semantics. Thus, plans are part of the input, so their complexity needs to be tamed (unlike in the satisfiability problem, where other tricks can be used like guessing a proper plan). Therein, it is also discussed how to incorporate other constraints into the plans, more precisely, the semantics of knowing how modalities is enriched with regularity constraints (i.e., where plans are given by some regular formalism) and numerical constraints (i.e., where actions in knowing how are restricted by some budget). 

The work in \cite{DemriF23}~paves the way for studying additional constraints, particularly knowing how to achieve a goal with a certain probability. Similar to the parallelism between (constrained) planning and (constrained) knowing how, the ability to handle probabilities in the context of knowing how serves as the logical counterpart to probabilistic planning (see, e.g.,~\cite{MadaniHC99}) and related concepts. Moreover, there is a realm of logics featuring probabilistic notions of strategic reasoning. For instance, \cite{BaierAFK18} discusses the idea of model-checking with probabilities, while those specifically related to ATL are explored in~\cite{BA95,TJ07,BullingJ09}. Also, probabilistic strategy logics are investigated in~\cite{AKMM19}, and~\cite{BerthonKMM24} considers stochastic natural strategic abilities, just to name a few.

Here, we present extensions of knowing how logics with probabilities. The new modality, written $\kh_q(\psi,\varphi)$, will be read as \emph{the agent knows how to achieve $\varphi$ given $\psi$, with a probability of at least $q$}. This idea results helpful in modeling case studies where the result of actions have a random component. A simple example of this is given in \cite{Kushmerick1995},  consider a robot that has to grasp an element,  the result of the robot's actions stochastically depends of the state of the world, for instance,  if the gripper is wet then there is  a probability of $0.9$ that the object falls if the robot tries to pick it up.  Thus the robot may try to dry the gripper before picking up elements.   This kind of scenarios can be modeled with Probabilistic LTS (PLTS), i.e., transition systems where now transitions are defined over states into probability distributions, where the latter indicates the probability of the actions' output. 

We start by naturally extending the logic over linear plans from~\cite{Wang15lori,Wang16,Wang2016}.  For this logic we show that in the limit case of taking the knowing how with a probability of $1$, we are back in the non-probabilistic case. We prove that the model-checking for the new logic is undecidable,  which contrasts  with the $\PSPACE$-complete complexity of the base logic. The proof strategy relies on the emptiness problem for probabilistic automata (see~\cite{MadaniHC99}). Then, we extend with probabilities the knowing how logic over LTS with indistinguishably classes. In this case, we can devise at least two cases.  First, we directly add probabilities to the logic presented in~\cite{AFSVQ21,AFSVQ23}. In this case, what we call \emph{non-adaptative}, the model-checking problem becomes undecidable  contrasting the complexity of model checking the original logic, which is in  $\PTIME$. This is proven by using a similar technique as in the previous extension. The second proposal, called here \emph{adaptative}, is arguably suitable to model scenarios in which the agent has the ability to choose between one plan or another, even if she considers them equally good. TBC \raul{otra vez, estaria bueno ejemplificar}. For this case, we get that the model-checking problem is in $\PTIME$, another appealing characteristic of this logic. Along the paper, we discuss a running example to illustrate not only the behaviour of the logics, but also the design decisions we made. 

Finally, we  have implemented the algorithms for the decidable cases into PRISM tool,  the prototype is presented in Section \ref{} along with its application to some case studies. 
\iffalse
---------- 

Here we list some important pieces of work, motivating ours:

\begin{itemize}
    % \item Knowing how has been investigated is the last years, from different perspectives, especially by combining epistemic operators of knowing that with operators describing abilities~\cite{Mccarthy69,Moore85,Les00,Hoek00,HerzigT06}. This is not considered as a proper reading~\cite{JamrogaA07,Herzig15}
    % \item In~\cite{Wang15lori,Wang16,Wang2016} a new perspective on knowing how emerged, in which a new modality is specifically defined with the purpose of capturing this concept.
    % \item This raised a family of logics, witnessed by all related work (see e.g.~\cite{LiWang17,Li17,Li17bis,FervariHLW17,LiW21,NaumovT17,NaumovT18,NaumovT19,Naumov2018a}).
    % \item A notion of `epistemic indistinguishability' is missing, arguably fixed by~\cite{AFSVQ21,AFSVQ23}.
    % \item With this at hand, it was possible to define dynamic epistemic modalities (e.g.~\cite{AFSV22}).
    % \item Constraints on plans, like regularity or budget constraints~\cite{DemriF23}.
    % \item The latter opens the path to study other constraints, in particular, \emph{knowing how to achieve a goal with a certain probability}.
    \item Relate to other epistemic based logics with probabilities, and with the version of knowing how with uncertainty~\cite{NaumovT19}. Recall the differences, and the case of use that we are able to capture.
    % \item Relate to planning with probabilities.
    % \item Model-checking with probabilities \cite{BaierAFK18}, related to ATL \cite{BA95,TJ07,BullingJ09}, strategy logics \cite{AKMM19}, stochastic natural strategic abilities \cite{BerthonKMM24}
    \item Recall the different versions of our modality, how we obtain a decidable logic, and why it makes sense.
    \item Connections with reinforcement learning and reasoning about such scenarios.
\end{itemize}
\fi