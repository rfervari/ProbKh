\section{Introduction}
\label{sec:intro}

Modern approaches in Epistemic Logic~\cite{Hintikka:1962} have shifted focus from a single notion of knowledge (usually, the notion of \emph{knowing that}) to a diverse palette of notions, each of them tailored to specific purposes. In this regard, the notion of \emph{knowing how} has received significant attention, since it captures scenarios related to intelligent agents and its strategic behaviour. Logically, knowing how is typically defined as the ability of an agent to achieve a certain goal.  Knowing-how logics have direct applications to \emph{planning} problems \cite{Stuart21},  where  plans have to be constructed such that a collection of agents can achieve a given goal.  Examples of planning applications can be found in e.g. self driving cars,  robotics,  conversational agents,  cybersecurity,  risk management,  etc.

Usually,  the semantics for knowing-how logics can be thought as a combination of operators that describe abilities alongside standard epistemic operators for knowing that.  This is the approach introduced in, e.g.~\cite{Mccarthy69,Moore85,Les00,Hoek00,HerzigT06}. As a result,  knowing how reflects that \emph{the agent knows that there is a course of action leading to achieve the intended goal}. However,  as pointed out in e.g.~\cite{JamrogaA07,Herzig15}, this reading is not entirely accurate.  Instead, knowing how could be read as \emph{there is a course of action, that the agent knows how to apply, to bring about the goal}. Thus, a novel perspective emerged in~\cite{Wang15lori,Wang16,Wang2016}, where a new modality is defined with the aim of capturing the proper reading of knowing how. 

More specifically, the new modality under consideration is a binary modality $\kh(\psi,\varphi)$ interpreted over Labeled Transition Systems (LTS), where an LTS models the  actions that are available to the agents as well as the effects of these actions. Thus,  the formula $\kh(\psi,\varphi)$ holds if there exists a sequence of actions $\plan$ (i.e., a \emph{plan}) such that,  in every situation where $\psi$ holds, $\plan$ can be executed, it never aborts its execution, and it always leads to situations in which $\varphi$ holds. This new view of knowing how raised a new family of logics refining the original one, witnessed by the extensive related literature (see e.g.~\cite{LiWang17,Li17,FervariHLW17,NaumovT19,Naumov2018a}). Interestingly, in~\cite{AFSVQ21,AFSVQ23} the original approach is enriched by a notion of `epistemic indistinguishability' between plans, arguably closer to standard semantics of epistemic logics. This indistinguishability relation indicates that all the related plans are considered or perceived ``equally good''
from the agent's perspective (even if they are not), thus a plan $\plan$ is suitable for achieving a goal if this is also the case for all the plans that are indistinguishable from $\plan$. The new semantics arguably offers a more adequate view of knowing how from an epistemic perspective, compared to the original approach.

The above-mentioned works investigate various logical properties, including axiomatizations, expressivity, and the complexity of the respective logics. In particular, the model-checking problem results of interest, since it is  ubiquitous in software verification but also an important tool for controller synthesis and planning. Moreover, as argued in~\cite{DF23}, the model-checking problem better reflects the real power of the logics. This is because these logics often have a simple syntax combined with a rich semantics. In model-checking, plans are part of the input, so the complexity needs to be tamed (unlike in the satisfiability problem, where other tricks can be used like guessing a proper plan). Therein,  the authors also discuss how to incorporate other constraints into the plans, more precisely, the different semantics of knowing how modalities are enriched with regularity constraints (i.e., where plans are given by some regular formalism) and numerical constraints (i.e., where actions in knowing how are restricted by some budget). 

The work in~\cite{DF23} paves the way for studying additional constraints, particularly knowing how to achieve a goal with a certain probability. This is of interest in scenarios where plans might lead to unexpected results due to a faulty behavior of actions,  or because their executions lead to random outcomes. Just as (constrained) planning is connected to (constrained) knowing-how, the ability to handle probabilities in the context of knowing how serves as the logical counterpart to probabilistic planning (see, e.g.,~\cite{MadaniHC99}) and related concepts. Moreover, there is a realm of logics featuring probabilistic notions of strategic reasoning. For instance, \cite{BaierAFK18} discusses the idea of model-checking with probabilities, while those specifically related to ATL are explored in~\cite{BA95,TJ07,BullingJ09}. Also, probabilistic strategy logics are investigated in~\cite{AKMM19}, while~\cite{BerthonKMM24} considers stochastic natural strategic abilities. % just to name a few.

Here, we present extensions of knowing how logics with probabilities. The new modality, written $\kh_q(\psi,\varphi)$, will be read as \emph{the agent knows how to achieve $\varphi$ given $\psi$, with a probability of at least $q$}. This idea results helpful in modeling case studies where the result of actions have a random component. A simple example of this situation is given in \cite{Kushmerick1995}: consider a robot that has to grasp an object,  the result of the robot's actions stochastically depends on the state of the world. For instance,  if the gripper is wet,  there is  a probability of $0.9$ that the object falls when the robot tries to pick it up.  Thus,  the robot may try to dry the gripper before picking up elements.   These kinds of scenarios can be modeled with Probabilistic LTS (PLTS), i.e., transition systems where now transitions relate states with probability distributions,  which in turn  capture the stochastic behavior of actions.

We start in~\Cref{subsec:prob:linear} by naturally extending the logic over linear plans from~\cite{Wang15lori,Wang16,Wang2016}.  For this logic we show that, under non-probabilistic models (i.e., LTSs), it agrees with the non-probabilistic case. We prove that the model-checking problem for the new logic is undecidable,  which contrasts  with the $\PSPACE$-complete complexity of the base logic. The proof strategy relies on the emptiness problem for probabilistic automata~\cite{MadaniHC99}. Then, we extend with probabilities the knowing-how logic over LTS with indistinguishability classes, for which we have devised two cases.  First (\Cref{subsec:prob:indist:committed}), we directly add probabilities to the logic presented in~\cite{AFSVQ21}.  In this case,  that we call \emph{non-adaptative}, the model-checking problem becomes undecidable  contrasting the complexity of model checking the original logic, which is in  $\PTIME$. This is proven by using a variant of the result in~\cite{MadaniHC99}. The second proposal (\Cref{subsec:prob:indist:adaptive}), called here \emph{adaptative}, is arguably suitable to model scenarios in which the agent has the ability to choose between one plan or another, among those that are considered equally good, depending on the particular situation. In fact, we compare expressivenes of all three logics with indistinguishability which helps to understand their utility. Also, for the adaptive case, 
we get that the model-checking problem is in $\PTIME$, another appealing characteristic of this logic. Along the paper, we discuss a running example to illustrate not only the behaviour of the logics, but also our design decisions.  
% \emph{Omitted proofs are included in the supplementary material.}
% Finally, we  have implemented the algorithms for the decidable cases into PRISM tool,  the prototype is presented in Section \ref{} along with its application to some case studies. 
\iffalse
---------- 

Here we list some important pieces of work, motivating ours:

\begin{itemize}
    % \item Knowing how has been investigated is the last years, from different perspectives, especially by combining epistemic operators of knowing that with operators describing abilities~\cite{Mccarthy69,Moore85,Les00,Hoek00,HerzigT06}. This is not considered as a proper reading~\cite{JamrogaA07,Herzig15}
    % \item In~\cite{Wang15lori,Wang16,Wang2016} a new perspective on knowing how emerged, in which a new modality is specifically defined with the purpose of capturing this concept.
    % \item This raised a family of logics, witnessed by all related work (see e.g.~\cite{LiWang17,Li17,Li17bis,FervariHLW17,LiW21,NaumovT17,NaumovT18,NaumovT19,Naumov2018a}).
    % \item A notion of `epistemic indistinguishability' is missing, arguably fixed by~\cite{AFSVQ21,AFSVQ23}.
    % \item With this at hand, it was possible to define dynamic epistemic modalities (e.g.~\cite{AFSV22}).
    % \item Constraints on plans, like regularity or budget constraints~\cite{DemriF23}.
    % \item The latter opens the path to study other constraints, in particular, \emph{knowing how to achieve a goal with a certain probability}.
    \item Relate to other epistemic based logics with probabilities, and with the version of knowing how with uncertainty~\cite{NaumovT19}. Recall the differences, and the case of use that we are able to capture.
    % \item Relate to planning with probabilities.
    % \item Model-checking with probabilities \cite{BaierAFK18}, related to ATL \cite{BA95,TJ07,BullingJ09}, strategy logics \cite{AKMM19}, stochastic natural strategic abilities \cite{BerthonKMM24}
    \item Recall the different versions of our modality, how we obtain a decidable logic, and why it makes sense.
    \item Connections with reinforcement learning and reasoning about such scenarios.
\end{itemize}
\fi
